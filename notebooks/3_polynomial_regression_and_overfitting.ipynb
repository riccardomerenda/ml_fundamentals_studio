{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression and Overfitting\n",
    "\n",
    "This notebook explores polynomial regression and the bias-variance tradeoff. We'll visualize how model complexity affects overfitting and underfitting, and learn to identify the optimal model complexity.\n",
    "\n",
    "Topics covered:\n",
    "1. Creating synthetic non-linear data\n",
    "2. Implementing and fitting polynomial regression models\n",
    "3. Visualizing underfitting, good fit, and overfitting\n",
    "4. Analyzing the bias-variance tradeoff\n",
    "5. Finding the optimal polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Add the parent directory to sys.path to import our custom modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our implementations\n",
    "from models.polynomial_regression import PolynomialRegression\n",
    "from utils.plotting import plot_regression_results, plot_overfitting_curve\n",
    "from datasets.data_utils import generate_synthetic_data, train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Non-Linear Data\n",
    "\n",
    "Let's create synthetic data with a non-linear relationship to demonstrate polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nonlinear_data(n_samples=100, function_type='polynomial', noise=0.5, x_range=(-3, 3)):\n",
    "    \"\"\"Generate synthetic non-linear data.\"\"\"\n",
    "    # Generate x values within the specified range\n",
    "    X = np.linspace(x_range[0], x_range[1], n_samples)\n",
    "    \n",
    "    # Generate y based on the function type\n",
    "    if function_type == 'polynomial':\n",
    "        # y = 0.5*x^3 - 2*x^2 + 1.5*x + 2 + noise\n",
    "        y = 0.5 * X**3 - 2 * X**2 + 1.5 * X + 2\n",
    "    elif function_type == 'sine':\n",
    "        # y = sin(x) + 0.5*x + noise\n",
    "        y = np.sin(2 * X) + 0.5 * X\n",
    "    elif function_type == 'exponential':\n",
    "        # y = e^(0.5*x) + noise\n",
    "        y = np.exp(0.5 * X)\n",
    "        # Clip extreme values\n",
    "        y = np.clip(y, 0, 100)  \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function type: {function_type}\")\n",
    "    \n",
    "    # Add noise\n",
    "    y += np.random.randn(n_samples) * noise\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data for a polynomial function\n",
    "X_poly, y_poly = generate_nonlinear_data(n_samples=100, function_type='polynomial', noise=1.0)\n",
    "\n",
    "# Generate data for a sine function\n",
    "X_sine, y_sine = generate_nonlinear_data(n_samples=100, function_type='sine', noise=0.3)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_poly, y_poly, alpha=0.7)\n",
    "plt.title('Polynomial Function Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_sine, y_sine, alpha=0.7)\n",
    "plt.title('Sine Function Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial Regression with Different Degrees\n",
    "\n",
    "Let's fit polynomial regression models of different degrees to see how the fit changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check if input data contains NaNs\n",
    "import numpy as np\n",
    "\n",
    "# Check and clean input data\n",
    "print(f\"NaNs in X_poly: {np.isnan(X_poly).any()}\")\n",
    "print(f\"NaNs in y_poly: {np.isnan(y_poly).any()}\")\n",
    "\n",
    "# Clean data if needed\n",
    "X_poly = np.nan_to_num(X_poly)\n",
    "y_poly = np.nan_to_num(y_poly)\n",
    "\n",
    "# Split the polynomial data into training and validation sets\n",
    "X_train_poly, X_val_poly, y_train_poly, y_val_poly = train_test_split(X_poly, y_poly, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reshape X for our model (expects 2D input)\n",
    "X_train_poly = X_train_poly.reshape(-1, 1)\n",
    "X_val_poly = X_val_poly.reshape(-1, 1)\n",
    "\n",
    "# Train polynomial regression models with different degrees\n",
    "degrees = [1, 2, 3]\n",
    "models_poly = []\n",
    "train_mse_poly = []\n",
    "val_mse_poly = []\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create and train model\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000)\n",
    "    model.fit(X_train_poly, y_train_poly)\n",
    "    models_poly.append(model)\n",
    "    \n",
    "    # Compute MSE on training and validation sets\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_val_pred = model.predict(X_val_poly)\n",
    "    \n",
    "    # Check for NaNs in predictions\n",
    "    if np.isnan(y_train_pred).any() or np.isnan(y_val_pred).any():\n",
    "        print(f\"NaN values detected in predictions for degree {degree}\")\n",
    "        # Replace NaNs with zeros or some other value for visualization\n",
    "        y_train_pred = np.nan_to_num(y_train_pred)\n",
    "        y_val_pred = np.nan_to_num(y_val_pred)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train_poly, y_train_pred)\n",
    "    val_mse = mean_squared_error(y_val_poly, y_val_pred)\n",
    "    \n",
    "    train_mse_poly.append(train_mse)\n",
    "    val_mse_poly.append(val_mse)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    \n",
    "    # Plot training data\n",
    "    plt.scatter(X_train_poly, y_train_poly, color='blue', alpha=0.6, label='Training data')\n",
    "    \n",
    "    # Plot validation data\n",
    "    plt.scatter(X_val_poly, y_val_poly, color='green', alpha=0.6, label='Validation data')\n",
    "    \n",
    "    # Plot the model predictions on a smooth curve\n",
    "    X_plot = np.linspace(min(X_poly), max(X_poly), 100).reshape(-1, 1)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    \n",
    "    # Check for NaNs in plot predictions\n",
    "    if np.isnan(y_plot).any():\n",
    "        y_plot = np.nan_to_num(y_plot)\n",
    "    \n",
    "    plt.plot(X_plot, y_plot, 'r-', linewidth=2, label=f'Degree {degree} model')\n",
    "    \n",
    "    plt.title(f'Polynomial Regression (Degree {degree})\\nTrain MSE: {train_mse:.2f}, Val MSE: {val_mse:.2f}')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Bias-Variance Tradeoff\n",
    "\n",
    "Let's plot the training and validation errors as a function of model complexity to visualize the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more degrees to better visualize the trend\n",
    "degrees_extended = list(range(1, 3))\n",
    "train_mse_extended = []\n",
    "val_mse_extended = []\n",
    "\n",
    "for degree in degrees_extended:\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000)\n",
    "    model.fit(X_train_poly, y_train_poly)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_val_pred = model.predict(X_val_poly)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train_poly, y_train_pred)\n",
    "    val_mse = mean_squared_error(y_val_poly, y_val_pred)\n",
    "    \n",
    "    train_mse_extended.append(train_mse)\n",
    "    val_mse_extended.append(val_mse)\n",
    "\n",
    "# Plot the error curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(degrees_extended, train_mse_extended, 'bo-', linewidth=2, label='Training MSE')\n",
    "plt.plot(degrees_extended, val_mse_extended, 'ro-', linewidth=2, label='Validation MSE')\n",
    "\n",
    "# Identify the optimal degree (lowest validation error)\n",
    "optimal_degree = degrees_extended[np.argmin(val_mse_extended)]\n",
    "min_val_mse = min(val_mse_extended)\n",
    "\n",
    "# Highlight the optimal degree\n",
    "plt.axvline(x=optimal_degree, color='green', linestyle='--', label=f'Optimal degree: {optimal_degree}')\n",
    "plt.scatter([optimal_degree], [min_val_mse], s=100, color='green')\n",
    "\n",
    "# Annotate regions\n",
    "plt.annotate('Underfitting\\n(High Bias)', xy=(2, max(train_mse_extended[:5]) * 0.8), \n",
    "             xytext=(2, max(train_mse_extended[:5]) * 0.8), fontsize=12, ha='center')\n",
    "\n",
    "plt.annotate('Overfitting\\n(High Variance)', xy=(15, min(val_mse_extended) * 2), \n",
    "             xytext=(15, min(val_mse_extended) * 2), fontsize=12, ha='center')\n",
    "\n",
    "plt.annotate('Optimal\\nModel Complexity', xy=(optimal_degree, min_val_mse * 0.5),\n",
    "             xytext=(optimal_degree, min_val_mse * 0.5), fontsize=12, ha='center')\n",
    "\n",
    "plt.title('Bias-Variance Tradeoff for Polynomial Regression')\n",
    "plt.xlabel('Polynomial Degree (Model Complexity)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xticks(degrees_extended)\n",
    "plt.ylim(0, max(val_mse_extended) * 1.2)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal polynomial degree: {optimal_degree}\")\n",
    "print(f\"Training MSE at optimal degree: {train_mse_extended[optimal_degree-1]:.2f}\")\n",
    "print(f\"Validation MSE at optimal degree: {val_mse_extended[optimal_degree-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Curve Analysis\n",
    "\n",
    "Let's look at how the training progresses for different model complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and track the learning curves\n",
    "degrees_for_curves = [1, optimal_degree, 3]  # Underfitting, optimal, overfitting\n",
    "models_curves = []\n",
    "\n",
    "for degree in degrees_for_curves:\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000, store_history=True)\n",
    "    model.fit(X_train_poly, y_train_poly)\n",
    "    models_curves.append(model)\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, (model, degree) in enumerate(zip(models_curves, degrees_for_curves)):\n",
    "    label = 'Underfitting (Linear)' if degree == 1 else \\\n",
    "            'Optimal Fit' if degree == optimal_degree else \\\n",
    "            'Overfitting (High Degree)'\n",
    "    plt.plot(model.cost_history, label=f'{label} (Degree {degree})')\n",
    "\n",
    "plt.title('Learning Curves for Different Model Complexities')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 50)  # Adjust as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Learning Curves with Training Set Size\n",
    "\n",
    "Now let's examine how model performance changes with training set size for different polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate more data for this experiment\n",
    "X_more, y_more = generate_nonlinear_data(n_samples=300, function_type='polynomial', noise=1.0)\n",
    "X_more = X_more.reshape(-1, 1)  # Reshape for our model\n",
    "\n",
    "# Split into training and validation\n",
    "X_train_more, X_val_more, y_train_more, y_val_more = train_test_split(X_more, y_more, test_size=0.3, random_state=42)\n",
    "\n",
    "# Try different training set sizes\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)  # From 10% to 100% of training data\n",
    "degrees_learning = [1, optimal_degree, 3]  # Linear, optimal, high-degree\n",
    "\n",
    "# Store results\n",
    "train_mse_by_size = {degree: [] for degree in degrees_learning}\n",
    "val_mse_by_size = {degree: [] for degree in degrees_learning}\n",
    "\n",
    "for size in train_sizes:\n",
    "    # Create a subset of the training data\n",
    "    n_samples = int(len(X_train_more) * size)\n",
    "    X_train_subset = X_train_more[:n_samples]\n",
    "    y_train_subset = y_train_more[:n_samples]\n",
    "    \n",
    "    for degree in degrees_learning:\n",
    "        # Train model on subset\n",
    "        model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000)\n",
    "        model.fit(X_train_subset, y_train_subset)\n",
    "        \n",
    "        # Evaluate on training subset and validation set\n",
    "        train_pred = model.predict(X_train_subset)\n",
    "        val_pred = model.predict(X_val_more)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train_subset, train_pred)\n",
    "        val_mse = mean_squared_error(y_val_more, val_pred)\n",
    "        \n",
    "        train_mse_by_size[degree].append(train_mse)\n",
    "        val_mse_by_size[degree].append(val_mse)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "for i, degree in enumerate(degrees_learning):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    plt.plot(train_sizes * 100, train_mse_by_size[degree], 'b-o', label='Training error')\n",
    "    plt.plot(train_sizes * 100, val_mse_by_size[degree], 'r-o', label='Validation error')\n",
    "    \n",
    "    plt.title(f'Learning Curves for Degree {degree}')\n",
    "    plt.xlabel('Training Set Size (%)')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 50)  # Adjust as needed\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Boundaries and Model Predictions\n",
    "\n",
    "Let's visualize the decision boundaries and prediction confidence for different model complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models with different complexities\n",
    "models_final = []\n",
    "degrees_final = [1, optimal_degree, 3]  # Linear, optimal, high-degree\n",
    "descriptions = ['Underfit (Linear)', 'Optimal Fit', 'Overfit (High Degree)']\n",
    "\n",
    "for degree in degrees_final:\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000)\n",
    "    model.fit(X_train_poly, y_train_poly)\n",
    "    models_final.append(model)\n",
    "\n",
    "# Create a smooth curve for plotting\n",
    "X_smooth = np.linspace(min(X_poly) - 0.5, max(X_poly) + 0.5, 1000).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i, (model, degree, desc) in enumerate(zip(models_final, degrees_final, descriptions)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    # Plot data points\n",
    "    plt.scatter(X_train_poly, y_train_poly, color='blue', alpha=0.5, label='Training data')\n",
    "    plt.scatter(X_val_poly, y_val_poly, color='green', alpha=0.5, label='Validation data')\n",
    "    \n",
    "    # Plot model prediction\n",
    "    y_smooth = model.predict(X_smooth)\n",
    "    plt.plot(X_smooth, y_smooth, 'r-', linewidth=2, label=f'Degree {degree} model')\n",
    "    \n",
    "    # Calculate MSE\n",
    "    train_pred = model.predict(X_train_poly)\n",
    "    val_pred = model.predict(X_val_poly)\n",
    "    train_mse = mean_squared_error(y_train_poly, train_pred)\n",
    "    val_mse = mean_squared_error(y_val_poly, val_pred)\n",
    "    \n",
    "    plt.title(f'{desc} (Degree {degree})\\nTrain MSE: {train_mse:.2f}, Val MSE: {val_mse:.2f}')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Different Non-Linear Function: Sine Wave\n",
    "\n",
    "Let's repeat our analysis with a sine wave function to see how polynomial regression handles different types of non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the sine wave data\n",
    "X_sine = X_sine.reshape(-1, 1)\n",
    "\n",
    "# Split the sine data into training and validation\n",
    "X_train_sine, X_val_sine, y_train_sine, y_val_sine = train_test_split(X_sine, y_sine, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train models with different polynomial degrees\n",
    "degrees_sine = [1, 2, 3]\n",
    "train_mse_sine = []\n",
    "val_mse_sine = []\n",
    "\n",
    "for degree in degrees_sine:\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, max_iterations=5000)\n",
    "    model.fit(X_train_sine, y_train_sine)\n",
    "    \n",
    "    train_pred = model.predict(X_train_sine)\n",
    "    val_pred = model.predict(X_val_sine)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train_sine, train_pred)\n",
    "    val_mse = mean_squared_error(y_val_sine, val_pred)\n",
    "    \n",
    "    train_mse_sine.append(train_mse)\n",
    "    val_mse_sine.append(val_mse)\n",
    "\n",
    "# Plot MSE vs. polynomial degree\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(degrees_sine, train_mse_sine, 'bo-', linewidth=2, label='Training MSE')\n",
    "plt.plot(degrees_sine, val_mse_sine, 'ro-', linewidth=2, label='Validation MSE')\n",
    "\n",
    "# Find the optimal degree\n",
    "optimal_degree_sine = degrees_sine[np.argmin(val_mse_sine)]\n",
    "plt.axvline(x=optimal_degree_sine, color='green', linestyle='--', label=f'Optimal degree: {optimal_degree_sine}')\n",
    "\n",
    "plt.title('Bias-Variance Tradeoff for Sine Wave Data')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xticks(degrees_sine)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the best fit\n",
    "best_model_sine = PolynomialRegression(degree=optimal_degree_sine, learning_rate=0.01, max_iterations=5000)\n",
    "best_model_sine.fit(X_train_sine, y_train_sine)\n",
    "\n",
    "# Create a smooth curve for plotting\n",
    "X_smooth_sine = np.linspace(min(X_sine) - 0.5, max(X_sine) + 0.5, 1000).reshape(-1, 1)\n",
    "y_smooth_sine = best_model_sine.predict(X_smooth_sine)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_sine, y_train_sine, color='blue', alpha=0.6, label='Training data')\n",
    "plt.scatter(X_val_sine, y_val_sine, color='green', alpha=0.6, label='Validation data')\n",
    "plt.plot(X_smooth_sine, y_smooth_sine, 'r-', linewidth=2, label=f'Degree {optimal_degree_sine} model')\n",
    "\n",
    "plt.title(f'Best Polynomial Fit for Sine Wave (Degree {optimal_degree_sine})')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Overfitting and Underfitting\n",
    "\n",
    "Let's summarize what we've learned about the bias-variance tradeoff, underfitting, and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "1. **Underfitting (High Bias)**\n",
    "   - Occurs when the model is too simple to capture the underlying pattern in the data\n",
    "   - Symptoms: high training error, high validation error\n",
    "   - Example: Using a linear model (degree 1) to fit a cubic function\n",
    "   - Adding more training data doesn't help much\n",
    "\n",
    "2. **Overfitting (High Variance)**\n",
    "   - Occurs when the model is too complex and captures noise in the training data\n",
    "   - Symptoms: low training error, high validation error, large gap between training and validation error\n",
    "   - Example: Using a very high-degree polynomial to fit a simpler function\n",
    "   - Adding more training data can help\n",
    "\n",
    "3. **Optimal Model Complexity**\n",
    "   - Balances underfitting and overfitting\n",
    "   - Symptoms: moderate training error, lowest validation error\n",
    "   - Example: Using a degree-3 polynomial to fit a cubic function\n",
    "   - Generalizes well to new data\n",
    "\n",
    "4. **Training Set Size Effects**\n",
    "   - Complex models require more training data to avoid overfitting\n",
    "   - Simple models may underfit even with large training sets\n",
    "   - Learning curves for optimal models show training and validation errors converging as training set size increases\n",
    "\n",
    "5. **Different Function Types**\n",
    "   - The optimal polynomial degree depends on the underlying function\n",
    "   - Even for functions that aren't polynomials (like sine waves), polynomial regression can approximate them well with the right degree\n",
    "   - More complex functions generally require higher-degree polynomials\n",
    "\n",
    "### Practical Guidelines\n",
    "\n",
    "1. **Start Simple**\n",
    "   - Begin with a simple model and gradually increase complexity\n",
    "   - Compare performance on validation data at each step\n",
    "\n",
    "2. **Use Validation Sets**\n",
    "   - Always evaluate models on data they haven't seen during training\n",
    "   - Choose the model with the best validation performance, not training performance\n",
    "\n",
    "3. **Plot Learning Curves**\n",
    "   - Diagnose underfitting/overfitting by examining how errors change with training set size\n",
    "   - If training and validation errors are high and close together → underfitting\n",
    "   - If training error is low but validation error is high → overfitting\n",
    "\n",
    "4. **Collect More Data**\n",
    "   - If possible, collect more training data, especially when dealing with complex models\n",
    "   - More data helps complex models generalize better\n",
    "\n",
    "5. **Consider Regularization**\n",
    "   - Instead of reducing model complexity, regularization can help prevent overfitting while maintaining flexibility\n",
    "   - We'll explore this in the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
