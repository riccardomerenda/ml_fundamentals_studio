{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Techniques for Machine Learning\n",
    "\n",
    "In this notebook, we'll explore regularization techniques to combat overfitting in machine learning models. Regularization adds constraints to model parameters, effectively limiting model complexity while maintaining predictive power.\n",
    "\n",
    "We'll cover:\n",
    "1. The problem of overfitting and the need for regularization\n",
    "2. L2 regularization (Ridge) implementation and effects\n",
    "3. Parameter tuning for optimal regularization\n",
    "4. Visualizing how regularization affects model parameters and predictions\n",
    "5. Comparing regularized vs unregularized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our implementations\n",
    "from models.polynomial_regression import PolynomialRegression\n",
    "from utils.preprocessing import StandardScaler\n",
    "from utils.plotting import plot_regularization_path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Overfitting and the Need for Regularization\n",
    "\n",
    "When a model learns the training data too well, it captures noise rather than underlying patterns. This leads to poor performance on new, unseen data - a problem known as *overfitting*.\n",
    "\n",
    "Let's generate a dataset to demonstrate this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sinusoidal_data(n_samples=50, noise_level=1.0):\n",
    "    \"\"\"Generate sinusoidal data with noise\"\"\"\n",
    "    # Generate x values between -3 and 3\n",
    "    x = np.linspace(-3, 3, n_samples)\n",
    "    \n",
    "    # Generate true y values: a sine function\n",
    "    y_true = np.sin(x) + 0.3*x\n",
    "    \n",
    "    # Add noise to create the observed y values\n",
    "    y = y_true + np.random.normal(0, noise_level, size=n_samples)\n",
    "    \n",
    "    return x, y, y_true\n",
    "\n",
    "# Generate data\n",
    "x_data, y_data, y_true = generate_sinusoidal_data(n_samples=30, noise_level=0.4)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reshape for our models (expects 2D input)\n",
    "X_train_2d = X_train.reshape(-1, 1)\n",
    "X_test_2d = X_test.reshape(-1, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_data, y_true, 'g-', label='True function', linewidth=2)\n",
    "plt.scatter(X_train, y_train, color='blue', s=50, alpha=0.7, label='Training data')\n",
    "plt.scatter(X_test, y_test, color='red', s=50, alpha=0.7, label='Test data')\n",
    "plt.title('Sinusoidal Dataset with Noise')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's demonstrate overfitting by training polynomial regression models with different degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train polynomial models with different degrees\n",
    "degrees = [1, 2, 3]\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create and fit model without regularization\n",
    "    model = PolynomialRegression(degree=degree, learning_rate=0.01, \n",
    "                               max_iterations=10000, regularization=0.0)\n",
    "    model.fit(X_train_2d, y_train)\n",
    "    \n",
    "    # Make predictions for training and test sets\n",
    "    y_train_pred = model.predict(X_train_2d)\n",
    "    y_test_pred = model.predict(X_test_2d)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Create smooth curve for visualization\n",
    "    x_curve = np.linspace(min(x_data), max(x_data), 100).reshape(-1, 1)\n",
    "    y_curve = model.predict(x_curve)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(x_data, y_true, 'g-', label='True function', linewidth=2)\n",
    "    plt.scatter(X_train, y_train, color='blue', s=30, alpha=0.7, label='Training')\n",
    "    plt.scatter(X_test, y_test, color='red', s=30, alpha=0.7, label='Test')\n",
    "    plt.plot(x_curve, y_curve, 'k-', label=f'Degree {degree} model', linewidth=2)\n",
    "    plt.title(f'Polynomial Degree {degree}\\nTrain MSE: {train_mse:.3f}, Test MSE: {test_mse:.3f}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how higher degree polynomials fit the training data better\")\n",
    "print(\"but perform worse on test data - this is overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L2 Regularization (Ridge Regression)\n",
    "\n",
    "L2 regularization adds a penalty term to the cost function proportional to the sum of squared weights:\n",
    "\n",
    "$$J(\\mathbf{w}, b) = \\frac{1}{2m}\\sum_{i=1}^{m}(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}w_j^2$$\n",
    "\n",
    "Where:\n",
    "- $J(\\mathbf{w}, b)$ is the regularized cost function\n",
    "- The first term is the standard mean squared error\n",
    "- The second term is the regularization penalty\n",
    "- $\\lambda$ is the regularization parameter that controls penalty strength\n",
    "\n",
    "Let's apply regularization to our highest degree polynomial model and see how it affects performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different levels of regularization to a high-degree polynomial\n",
    "high_degree = 3  # High degree to demonstrate overfitting\n",
    "lambdas = [0, 0.001, 0.1, 10.0]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, lambda_val in enumerate(lambdas):\n",
    "    # Create and fit regularized model\n",
    "    model = PolynomialRegression(degree=high_degree, learning_rate=0.01, \n",
    "                               max_iterations=10000, regularization=lambda_val)\n",
    "    model.fit(X_train_2d, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_2d)\n",
    "    y_test_pred = model.predict(X_test_2d)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Calculate sum of squared weights (excluding bias)\n",
    "    weight_norm = np.sum(model.weights**2)\n",
    "    \n",
    "    # Create smooth curve for visualization\n",
    "    x_curve = np.linspace(min(x_data), max(x_data), 100).reshape(-1, 1)\n",
    "    y_curve = model.predict(x_curve)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(x_data, y_true, 'g-', label='True function', linewidth=2)\n",
    "    plt.scatter(X_train, y_train, color='blue', s=30, alpha=0.7, label='Training')\n",
    "    plt.scatter(X_test, y_test, color='red', s=30, alpha=0.7, label='Test')\n",
    "    plt.plot(x_curve, y_curve, 'k-', label=f'Degree {high_degree}, λ={lambda_val}', linewidth=2)\n",
    "    plt.title(f'L2 Regularization (λ={lambda_val})\\nTrain MSE: {train_mse:.3f}, Test MSE: {test_mse:.3f}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.ylim(-2.5, 2.5)  # Consistent y-axis for better comparison\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Effect of Regularization on Model Weights\n",
    "\n",
    "Regularization works by shrinking the model weights toward zero, with higher λ values causing more shrinkage. Let's examine how regularization affects the distribution of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded range of regularization values\n",
    "lambda_values = [0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "weight_norms = []\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "models = []\n",
    "\n",
    "for lam in lambda_values:\n",
    "    # Train model with this regularization strength\n",
    "    model = PolynomialRegression(degree=high_degree, learning_rate=0.01, \n",
    "                               max_iterations=10000, regularization=lam)\n",
    "    model.fit(X_train_2d, y_train)\n",
    "    models.append(model)\n",
    "    \n",
    "    # Calculate weight norm (L2 norm squared)\n",
    "    weight_norm = np.sum(model.weights**2)\n",
    "    weight_norms.append(weight_norm)\n",
    "    \n",
    "    # Calculate MSE on training and test sets\n",
    "    train_pred = model.predict(X_train_2d)\n",
    "    test_pred = model.predict(X_test_2d)\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    train_errors.append(train_mse)\n",
    "    test_errors.append(test_mse)\n",
    "\n",
    "# Plot weight magnitudes vs regularization parameter\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Weight norm vs regularization strength\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.loglog(lambda_values, weight_norms, 'bo-', linewidth=2)\n",
    "plt.xlabel('Regularization parameter (λ)')\n",
    "plt.ylabel('Sum of squared weights')\n",
    "plt.title('Effect of Regularization on Weight Magnitude')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Training and test errors vs regularization strength\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx(lambda_values, train_errors, 'bo-', linewidth=2, label='Training MSE')\n",
    "plt.semilogx(lambda_values, test_errors, 'ro-', linewidth=2, label='Test MSE')\n",
    "plt.xlabel('Regularization parameter (λ)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Error vs Regularization Strength')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal lambda value (minimizing test error)\n",
    "best_idx = np.argmin(test_errors)\n",
    "best_lambda = lambda_values[best_idx]\n",
    "print(f\"Optimal regularization parameter (λ): {best_lambda}\")\n",
    "print(f\"Test MSE at optimal λ: {test_errors[best_idx]:.4f}\")\n",
    "print(f\"Training MSE at optimal λ: {train_errors[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how individual weights change with different regularization strengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights from each model\n",
    "all_weights = np.array([model.weights for model in models])\n",
    "\n",
    "# Plot regularization path\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(all_weights.shape[1]):\n",
    "    plt.semilogx(lambda_values, all_weights[:, i], '.-', label=f'w{i+1}')\n",
    "    \n",
    "plt.axvline(x=best_lambda, color='black', linestyle='--', label='Optimal λ')\n",
    "plt.xlabel('Regularization parameter (λ)')\n",
    "plt.ylabel('Weight value')\n",
    "plt.title('Regularization Path: Weight Values vs λ')\n",
    "plt.grid(True)\n",
    "\n",
    "# Only show a subset of weights in the legend to avoid overcrowding\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "subset = list(range(0, len(handles), max(1, len(handles) // 10)))\n",
    "subset = subset + [len(handles)-1]  # Add the optimal lambda line\n",
    "plt.legend([handles[i] for i in subset], [labels[i] for i in subset], loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Performance with Optimal Regularization\n",
    "\n",
    "Now let's compare the model with no regularization, too much regularization, and optimal regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models with different regularization settings\n",
    "no_reg_idx = 0  # λ = 0\n",
    "optimal_reg_idx = best_idx  # Optimal λ\n",
    "high_reg_idx = len(lambda_values) - 1  # Highest λ\n",
    "\n",
    "# Extract the models\n",
    "model_no_reg = models[no_reg_idx]\n",
    "model_optimal = models[optimal_reg_idx]\n",
    "model_high_reg = models[high_reg_idx]\n",
    "\n",
    "# Create smooth curve for visualization\n",
    "x_curve = np.linspace(min(x_data) - 1, max(x_data) + 1, 200).reshape(-1, 1)\n",
    "y_no_reg = model_no_reg.predict(x_curve)\n",
    "y_optimal = model_optimal.predict(x_curve)\n",
    "y_high_reg = model_high_reg.predict(x_curve)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_data, y_true, 'g-', linewidth=3, label='True function')\n",
    "plt.plot(x_curve, y_no_reg, 'r--', linewidth=2, label=f'No regularization (λ=0), Test MSE: {test_errors[no_reg_idx]:.4f}')\n",
    "plt.plot(x_curve, y_optimal, 'b-', linewidth=2, label=f'Optimal regularization (λ={best_lambda}), Test MSE: {test_errors[optimal_reg_idx]:.4f}')\n",
    "plt.plot(x_curve, y_high_reg, 'k--', linewidth=2, label=f'High regularization (λ={lambda_values[high_reg_idx]}), Test MSE: {test_errors[high_reg_idx]:.4f}')\n",
    "plt.scatter(X_train, y_train, color='blue', s=50, alpha=0.5, label='Training data')\n",
    "plt.scatter(X_test, y_test, color='red', s=50, alpha=0.5, label='Test data')\n",
    "\n",
    "plt.title(f'Comparison of Models with Different Regularization (Degree {high_degree})')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-3, 3)  # Set consistent y-axis bounds\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combining Model Complexity and Regularization\n",
    "\n",
    "Now let's explore how model complexity (polynomial degree) and regularization interact. We'll find the optimal combination of both hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over polynomials and regularization\n",
    "degrees_grid = [1, 2, 3]\n",
    "lambdas_grid = [0, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# Initialize results grid\n",
    "results = np.zeros((len(degrees_grid), len(lambdas_grid)))\n",
    "\n",
    "# Train all combinations\n",
    "for i, degree in enumerate(degrees_grid):\n",
    "    for j, lambda_val in enumerate(lambdas_grid):\n",
    "        # Create and train model\n",
    "        model = PolynomialRegression(degree=degree, learning_rate=0.01, \n",
    "                                   max_iterations=10000, regularization=lambda_val)\n",
    "        model.fit(X_train_2d, y_train)\n",
    "        \n",
    "        # Calculate test error\n",
    "        y_test_pred = model.predict(X_test_2d)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        # Store result\n",
    "        results[i, j] = test_mse\n",
    "\n",
    "# Find the best combination\n",
    "min_idx = np.unravel_index(np.argmin(results), results.shape)\n",
    "best_degree = degrees_grid[min_idx[0]]\n",
    "best_lambda = lambdas_grid[min_idx[1]]\n",
    "\n",
    "# Plot results as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(results, cmap='viridis', aspect='auto', origin='lower')\n",
    "plt.colorbar(label='Test MSE')\n",
    "plt.title('Test MSE for Different Combinations of Degree and Regularization')\n",
    "plt.xlabel('Regularization Parameter (λ)')\n",
    "plt.ylabel('Polynomial Degree')\n",
    "plt.xticks(np.arange(len(lambdas_grid)), lambdas_grid)\n",
    "plt.yticks(np.arange(len(degrees_grid)), degrees_grid)\n",
    "\n",
    "# Mark the best combination\n",
    "plt.plot(min_idx[1], min_idx[0], 'ro', markersize=12)\n",
    "\n",
    "# Add text annotations with error values\n",
    "for i in range(len(degrees_grid)):\n",
    "    for j in range(len(lambdas_grid)):\n",
    "        plt.text(j, i, f'{results[i, j]:.2f}', ha='center', va='center', \n",
    "                color='white' if results[i, j] > np.median(results) else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best combination: Polynomial degree = {best_degree}, Regularization λ = {best_lambda}\")\n",
    "print(f\"Test MSE with optimal settings: {results[min_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing the Optimal Model\n",
    "\n",
    "Let's train the model with the optimal degree and regularization parameters and visualize its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimal model\n",
    "optimal_model = PolynomialRegression(degree=best_degree, learning_rate=0.01, \n",
    "                                   max_iterations=10000, regularization=best_lambda)\n",
    "optimal_model.fit(X_train_2d, y_train)\n",
    "\n",
    "# Calculate errors\n",
    "y_train_pred = optimal_model.predict(X_train_2d)\n",
    "y_test_pred = optimal_model.predict(X_test_2d)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Create smooth curve for visualization\n",
    "x_curve = np.linspace(min(x_data) - 1, max(x_data) + 1, 200).reshape(-1, 1)\n",
    "y_curve = optimal_model.predict(x_curve)\n",
    "\n",
    "# Plot optimal model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_data, y_true, 'g-', linewidth=3, label='True function')\n",
    "plt.scatter(X_train, y_train, color='blue', s=50, alpha=0.7, label='Training data')\n",
    "plt.scatter(X_test, y_test, color='red', s=50, alpha=0.7, label='Test data')\n",
    "plt.plot(x_curve, y_curve, 'k-', linewidth=2, label='Optimal model')\n",
    "\n",
    "plt.title(f'Optimal Model: Degree {best_degree}, λ={best_lambda}\\nTrain MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion: Key Regularization Insights\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **The Overfitting Problem**\n",
    "   - Without regularization, complex models (high-degree polynomials) tend to overfit training data\n",
    "   - Overfitted models have low training error but high test error\n",
    "   - Overfitting captures noise rather than the underlying pattern\n",
    "\n",
    "2. **L2 Regularization (Ridge)**\n",
    "   - Adds a penalty term proportional to the sum of squared weights\n",
    "   - Controls model complexity without reducing the number of features\n",
    "   - Shrinks weights toward zero, but typically doesn't eliminate them completely\n",
    "   - Controlled by the regularization parameter λ\n",
    "\n",
    "3. **Effect of Regularization Strength**\n",
    "   - λ = 0: No regularization, potential overfitting\n",
    "   - Small λ: Slight regularization, still flexible\n",
    "   - Optimal λ: Best balance between fitting data and constraining weights\n",
    "   - Large λ: Heavy regularization, can lead to underfitting\n",
    "\n",
    "4. **Model Complexity vs. Regularization**\n",
    "   - Higher complexity models (higher polynomial degrees) need stronger regularization\n",
    "   - Lower complexity models need less regularization\n",
    "   - The optimal combination provides the best generalization performance\n",
    "\n",
    "5. **Practical Guidelines**\n",
    "   - Use validation/test data to find optimal regularization strength\n",
    "   - Consider a grid search over both model complexity and regularization parameters\n",
    "   - Monitor both training and test error to detect overfitting\n",
    "   - Smaller weights generally lead to better generalization\n",
    "\n",
    "Regularization is a powerful technique that allows us to use complex models while preventing overfitting, resulting in models that generalize better to new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
